# LLM Infrastructure Capacity Forecasting

GPU ë° ì¸í”„ë¼ ìš©ëŸ‰ì„ ì˜ˆì¸¡í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. LLM ì¶”ë¡ (Inference) ë° íŒŒì¸íŠœë‹(Training) ì›Œí¬ë¡œë“œì— ëŒ€í•œ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

- ğŸ§  **LLM ì¶”ë¡  ìš©ëŸ‰ ì˜ˆì¸¡**: GPU ë©”ëª¨ë¦¬, TPS, ë ˆì´í„´ì‹œ, ë ˆí”Œë¦¬ì¹´ ìˆ˜ ê³„ì‚°
- ğŸ“ **íŒŒì¸íŠœë‹ ìš©ëŸ‰ ì˜ˆì¸¡**: í•™ìŠµ ì‹œê°„, GPU ìˆ˜, ë©”ëª¨ë¦¬ ë¶„ì„, ë¹„ìš© ì¶”ì •
- ğŸ“ˆ **ì‹œê³„ì—´ ì˜ˆì¸¡**: ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ë¯¸ë˜ ë¦¬ì†ŒìŠ¤ ìˆ˜ìš” ì˜ˆì¸¡ (STL, ARIMA, ETS)
- ğŸ’° **ë¹„ìš© ì¶”ì •**: AWS, GCP, Azure GPU ê°€ê²© ê¸°ë°˜ ë¹„ìš© ê³„ì‚°
- ğŸ“‹ **ì„œë¹„ìŠ¤ ê´€ë¦¬**: ì„œë¹„ìŠ¤ ë©”íƒ€ë°ì´í„°, ìš©ëŸ‰ ìš”ì²­ ì›Œí¬í”Œë¡œìš°

## ì„¤ì¹˜

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

## ì‚¬ìš©ë²•

### 1. Interactive ëª¨ë“œ (ëŒ€í™”í˜•)

```bash
python main.py
# ë˜ëŠ”
python commands/forecast.py
```

ë‹¨ê³„ë³„ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ë©° ìš©ëŸ‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤:
- ì›Œí¬ë¡œë“œ íƒ€ì… ì„ íƒ (inference/training)
- ëª¨ë¸ ì„¤ì • (í¬ê¸°, ì •ë°€ë„)
- ì›Œí¬ë¡œë“œ íŒŒë¼ë¯¸í„° ì…ë ¥
- GPU ì„¤ì • (ì„ íƒ)

### 2. JSON Config ëª¨ë“œ

```bash
# í…œí”Œë¦¿ ìƒì„±
python commands/forecast.py --generate-config inference
python commands/forecast.py --generate-config training

# ì„¤ì • íŒŒì¼ë¡œ ì‹¤í–‰
python commands/forecast.py --config inference_config.json

# CLI ì˜µì…˜ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ
python commands/forecast.py --config inference_config.json --rps 20.0
```

#### Inference ì„¤ì • ì˜ˆì‹œ (`inference_config.json`)

```json
{
  "mode": "inference",
  "workload": {
    "requests_per_second": 10.0,
    "avg_input_tokens": 500,
    "avg_output_tokens": 200,
    "peak_load_multiplier": 1.5
  },
  "model": {
    "model_size_billions": 70,
    "precision": "FP16",
    "context_window": 8192,
    "batch_size": 4
  },
  "gpu": {
    "gpu_type": "A100-80GB",
    "target_gpu_utilization": 0.7
  },
  "options": {
    "include_cost": true
  }
}
```

#### Training ì„¤ì • ì˜ˆì‹œ (`training_config.json`)

```json
{
  "mode": "training",
  "training": {
    "dataset_size_tokens": 1000000000,
    "sequence_length": 4096,
    "num_epochs": 3,
    "global_batch_size": 64,
    "optimizer_type": "AdamW",
    "gradient_checkpointing": true
  },
  "model": {
    "model_size_billions": 70,
    "precision": "BF16"
  },
  "gpu": {
    "gpu_type": "H100-80GB"
  }
}
```

### 3. CLI Args ëª¨ë“œ

#### Inference ëª¨ë“œ

```bash
python commands/forecast.py \
  --mode inference \
  --rps 10 \
  --input-tokens 500 \
  --output-tokens 200 \
  --model-size 70 \
  --precision FP16 \
  --gpu-type A100-80GB \
  --cost \
  --output inference_plan.json
```

#### Training ëª¨ë“œ

```bash
python commands/forecast.py \
  --mode training \
  --dataset-size 1000000000 \
  --sequence-length 4096 \
  --epochs 3 \
  --global-batch-size 64 \
  --model-size 70 \
  --precision BF16 \
  --optimizer AdamW \
  --gradient-checkpointing \
  --cost \
  --output training_plan.json
```

## ì¶œë ¥ ì˜ˆì‹œ

### Inference Capacity Plan

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ LLM INFERENCE CAPACITY PLAN
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š INPUT SUMMARY:
   Requests per Second: 10.0
   Input Tokens: 500
   Output Tokens: 200
   Model Size: 70B
   Precision: FP16

ğŸ–¥ï¸ GPU RESOURCES:
   GPU Memory per Replica: 175.94 GB
   GPUs per Replica: 4
   Recommended GPU: H100-80GB
   Replicas: 59 - 89
   Total GPUs: 236

âš¡ THROUGHPUT:
   TPS per Replica: 33.94
   Total TPS Capacity: 2002.17
   Max RPS Capacity: 10.01

â±ï¸ LATENCY:
   Est. TTFT: 50.64 ms
   Est. ITL: 63.95 ms

ğŸ’° COST ESTIMATES:
   Monthly GPU Cost: $509,760.00
   Cost per 1M Tokens: $98.2268
```

### Training Capacity Plan

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ LLM TRAINING CAPACITY PLAN
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š INPUT SUMMARY:
   Dataset Size: 1,000,000,000 tokens
   Sequence Length: 4096
   Epochs: 3
   Global Batch Size: 64
   Model Size: 70B
   Optimizer: Adam

ğŸ–¥ï¸ GPU MEMORY BREAKDOWN:
   Model Weights: 130.39 GB
   Gradients: 130.39 GB
   Optimizer States: 260.77 GB
   Activations: 36.51 GB
   Total per GPU: 18.10 GB

ğŸ”§ GPU REQUIREMENTS:
   Required GPUs: 64
   Recommended GPU: H100-80GB
   Nodes: 8 Ã— 8 GPUs

â±ï¸ TRAINING ESTIMATES:
   Duration: 11.0 hours (0.5 days)

ğŸ’° COST ESTIMATES:
   Total Training Cost: $2,121.21
   Cost per Epoch: $707.07
```

## Programmatic Usage

```python
from llm_forecast_engine import LLMForecastEngine
from models import LLMWorkloadInput, TrainingInput, ModelConfig, GPUConfig

engine = LLMForecastEngine()

# === Inference Mode ===
workload = LLMWorkloadInput(
    requests_per_second=10.0,
    avg_input_tokens=500,
    avg_output_tokens=200
)
model = ModelConfig(
    model_size_billions=70,
    precision="FP16"
)

inference_plan = engine.generate_inference_plan(workload, model, include_cost=True)
print(f"Total GPUs: {inference_plan.gpu_resources.total_gpus}")
print(f"Cost/M tokens: ${inference_plan.cost.cost_per_million_tokens:.4f}")

# === Training Mode ===
training = TrainingInput(
    dataset_size_tokens=1_000_000_000,
    sequence_length=4096,
    num_epochs=3,
    global_batch_size=64
)

training_plan = engine.generate_training_plan(training, model, include_cost=True)
print(f"Required GPUs: {training_plan.gpu_resources.required_gpus}")
print(f"Duration: {training_plan.training_metrics.estimated_duration_hours:.1f} hours")
print(f"Cost: ${training_plan.cost.total_training_cost:,.2f}")

# === GPU Comparison ===
comparison = engine.compare_gpu_options(workload, model)
for c in comparison:
    print(f"{c['gpu_type']}: {c['total_gpus']} GPUs, ${c['monthly_gpu_cost']:,.0f}/month")

# === Time-Series Forecasting ===
from datetime import datetime, timedelta

rps_history = [
    (datetime.now() - timedelta(days=30-i), 10 + i * 0.1)
    for i in range(30)
]
forecast = engine.forecast_future_needs(
    rps_history, model, horizon_days=30, scenario="pessimistic"
)
print(f"Scaling recommendation: {forecast['scaling_recommendations'][0]}")
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
resource_forecast/
â”œâ”€â”€ commands/
â”‚   â””â”€â”€ forecast.py          # CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”œâ”€â”€ models.py                 # ë°ì´í„° ëª¨ë¸ (Input/Output)
â”œâ”€â”€ config.py                 # GPU ìŠ¤í™, ê°€ê²©, ì„¤ì •ê°’
â”œâ”€â”€ config_loader.py          # JSON ì„¤ì • ë¡œë”
â”œâ”€â”€ inference_engine.py       # ì¶”ë¡  ìš©ëŸ‰ ì˜ˆì¸¡ ì—”ì§„
â”œâ”€â”€ training_engine.py        # í•™ìŠµ ìš©ëŸ‰ ì˜ˆì¸¡ ì—”ì§„
â”œâ”€â”€ forecasting.py            # ì‹œê³„ì—´ ì˜ˆì¸¡ ì—”ì§„
â”œâ”€â”€ services.py               # ì„œë¹„ìŠ¤ ê´€ë¦¬
â”œâ”€â”€ llm_forecast_engine.py    # í†µí•© ì—”ì§„
â”œâ”€â”€ llm_agent.py              # ì¸í„°ë™í‹°ë¸Œ ì—ì´ì „íŠ¸
â”œâ”€â”€ main.py                   # ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â””â”€â”€ spec-kit/                 # ìŠ¤í™ ë¬¸ì„œ
    â”œâ”€â”€ requirements.md
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ acceptance_criteria.md
    â””â”€â”€ work_plan.md
```

## ì§€ì› GPU

| GPU | ë©”ëª¨ë¦¬ | ê°€ê²©/ì‹œê°„ (AWS) |
|-----|--------|-----------------|
| A100-40GB | 40 GB | $1.10 |
| A100-80GB | 80 GB | $1.60 |
| H100-80GB | 80 GB | $3.00 |
| L4 | 24 GB | $0.50 |
| T4 | 16 GB | $0.35 |
| V100 | 32 GB | $0.90 |

## ì§€ì› ì •ë°€ë„

- FP32: 4 bytes/param
- FP16: 2 bytes/param
- BF16: 2 bytes/param
- INT8: 1 byte/param
- INT4: 0.5 bytes/param

## ê³„ì‚° ê³µì‹

### GPU ë©”ëª¨ë¦¬ (Inference)

```
GPU Memory = Model Weights + KV Cache + Activations + Overhead

Model Weights = model_params Ã— bytes_per_param
KV Cache = 2 Ã— num_layers Ã— hidden_dim Ã— context_length Ã— batch_size Ã— bytes_per_param
Activations â‰ˆ 15% of model weights
Overhead â‰ˆ 10%
```

### GPU ë©”ëª¨ë¦¬ (Training)

```
GPU Memory = Model Weights + Gradients + Optimizer States + Activations + Overhead

Gradients = Model Weights
Optimizer States:
  - Adam: 2 Ã— Model Weights
  - Adafactor: 0.5 Ã— Model Weights
  - SGD: 0
Activations = sequence_length Ã— batch_size Ã— hidden_dim Ã— num_layers Ã— bytes
```

### í•™ìŠµ ì‹œê°„

```
Training Duration = (Dataset Size Ã— Epochs) / (Tokens per Second per GPU Ã— Number of GPUs)
```

## ë¼ì´ì„ ìŠ¤

MIT License
